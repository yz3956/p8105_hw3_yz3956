---
title:  "Homework 3 solutions"
author: "Yali Zhai"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---
install.packages("devtools")
install.packages("hexbin")
devtools::install_github("p8105/p8105.datasets")
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(patchwork)
library(ggridges)
knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


### Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```


### Problem 2

```{r}
accel_df = 
  read.csv("./accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_num", 
     names_prefix = "activity_",
    values_to = "activity_counts") %>% 
  mutate(
    day_category = case_when(
      day %in% c("Monday", "Tuseday", "Wednesday", "Thursday", "Friday") ~ "Weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend",
      TRUE      ~ ""),
    activity_num = as.numeric(activity_num)
  ) %>% 
  relocate(day_id, week, day, day_category)
```

The resulting dataset has six variables: day ID, week, day, day category, activity number, activity counts. There are 50400 observations in this dataset.


Aggregate total and make a table.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(activity_total = sum(activity_counts)) %>% 
  knitr::kable()
```

I don't see any apparent trends.


Make a plot.

```{r}
accel_df %>% 
  ggplot( aes(x = activity_num, y = activity_counts, group = day_id, color = day, alpha = .5)) +
  geom_point() + geom_line() +
  labs(
    title = "24-hour activity plot",
    x = "time (minute)",
    y = "activity counts")
```

THe activity counts in daytime are higher than in midnight and the maximum of activity accounts usually appears in the period that from 8 p.m. to 10 p.m.


### Problem 3

```{r}
library(p8105.datasets)
data("ny_noaa")
view(ny_noaa)
```

Clean the data.

```{r}
ny_noaa_df = ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(
    tmax = as.numeric(tmax), 
    tmin = as.numeric(tmin))

ny_noaa_df %>% 
  count(snow) %>% 
  arrange(desc(n))
```

The units for temperature, precipitation, and snowfall are tenths of degrees C, tenths of mm and mm respectively, which are all  reasonable.
For snowfall, 0 is the most commonly observed value because in New York state, only winter has snowfall.


Make a two-panel plot.

```{r}
ny_noaa_df %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax)) %>% 
  mutate(
    year = as.numeric(year),
    month = as.numeric(month)
  ) %>% 
  filter(month %in% c(1, 7)) %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id)) +
  geom_point() +
  geom_line() +
  facet_grid(~month)
```


The mean temperature maximums in January and July fluctuated during the 30 years. In general, the values have gone up a little bit. For January, there is a outlier in 1982. For July, ther is a outlier in 1988.

```{r}
temp_plot = 
  ggplot(ny_noaa_df, aes(x = tmax, y = tmin)) + 
  geom_hex() +
  labs(
    title = "Temperature plot",
    x = "Minimum daily temperature (tenths of degrees C)",
    y = "Maxiumum daily temperature (tenths of degrees C)")

snow_plot = 
  ny_noaa_df %>% 
  filter(snow > 0, snow < 100) %>% 
  ggplot(aes(x = year, y = snow)) + 
  geom_violin() +
  labs(
    title = "Snowfall distribution",
    y = " Snowfall (mm)"
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

temp_plot + snow_plot
```

